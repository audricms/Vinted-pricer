{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5292ae4b-af4b-4fd2-8925-78f83c1e3da1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-25 17:24:20--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
      "Resolving dl.google.com (dl.google.com)... 64.233.167.136, 64.233.167.93, 64.233.167.190, ...\n",
      "Connecting to dl.google.com (dl.google.com)|64.233.167.136|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 104953176 (100M) [application/x-debian-package]\n",
      "Saving to: ‘/tmp/chrome.deb’\n",
      "\n",
      "/tmp/chrome.deb     100%[===================>] 100.09M  37.1MB/s    in 2.7s    \n",
      "\n",
      "2023-12-25 17:24:23 (37.1 MB/s) - ‘/tmp/chrome.deb’ saved [104953176/104953176]\n",
      "\n",
      "Hit:1 https://dl.google.com/linux/chrome/deb stable InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease  \n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease    \n",
      "Hit:6 https://apt.postgresql.org/pub/repos/apt jammy-pgdg InRelease\n",
      "Fetched 229 kB in 2s (98.9 kB/s)\n",
      "Reading package lists... Done\n",
      "W: https://apt.postgresql.org/pub/repos/apt/dists/jammy-pgdg/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'google-chrome-stable' instead of '/tmp/chrome.deb'\n",
      "google-chrome-stable is already the newest version (120.0.6099.129-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Requirement already satisfied: chromedriver-autoinstaller in /opt/mamba/lib/python3.10/site-packages (0.6.3)\n",
      "Requirement already satisfied: selenium in /opt/mamba/lib/python3.10/site-packages (4.16.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/mamba/lib/python3.10/site-packages (from chromedriver-autoinstaller) (23.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/mamba/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/mamba/lib/python3.10/site-packages (from selenium) (0.23.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/mamba/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/mamba/lib/python3.10/site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/mamba/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/mamba/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/mamba/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/opt/mamba/lib/python3.10/site-packages/chromedriver_autoinstaller/120/chromedriver'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -O /tmp/chrome.deb\n",
    "!sudo apt-get update\n",
    "!sudo -E apt-get install -y /tmp/chrome.deb\n",
    "!pip install chromedriver-autoinstaller selenium\n",
    "\n",
    "import chromedriver_autoinstaller\n",
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe2b8f25-00d7-49ce-9d00-bff651ec1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in /opt/mamba/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/mamba/lib/python3.10/site-packages (from webdriver_manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2cfc1b4-a594-4f9e-9ded-4d8c15b8faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/mamba/lib/python3.10/site-packages (4.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/mamba/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/mamba/lib/python3.10/site-packages (from selenium) (0.23.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/mamba/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/mamba/lib/python3.10/site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/mamba/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/mamba/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/mamba/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c816c05a-256a-45d1-8765-918d88806ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas\n",
    "\n",
    "import selenium\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "path_to_web_driver = ChromeDriverManager().install()\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "\n",
    "!pip install -q lxml\n",
    "\n",
    "import bs4\n",
    "import lxml\n",
    "import pandas\n",
    "import urllib\n",
    "\n",
    "from urllib import request\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "400bf72f-c730-4b4d-8cfc-4f014832d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "# Adding argument to disable the AutomationControlled flag \n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\") \n",
    " \n",
    "# Exclude the collection of enable-automation switches \n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"]) \n",
    " \n",
    "# Turn-off userAutomationExtension \n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False) \n",
    " \n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument(\"--user-agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f09112c6-7320-4003-974e-e118940e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=path_to_web_driver)\n",
    "\n",
    "browser = webdriver.Chrome(service=service,\n",
    "                           options=chrome_options)\n",
    "\n",
    "# Changing the property of the navigator value for webdriver to undefined \n",
    "browser.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31dfccae-fb41-43bf-aa26-eef62277fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableau(x) :\n",
    "\n",
    "    x = raw_to_url(x)\n",
    "    browser.get('https://www.vinted.fr/catalog?search_text='+x)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:  # handling cookies pop-upabs\n",
    "        Cookies = browser.find_element(By.ID, 'onetrust-accept-btn-handler')\n",
    "        Cookies.click()\n",
    "        time.sleep(2)  # let's be respectful !\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    n=3\n",
    "    scrapping = {}\n",
    "    \n",
    "    for i in range(1,n+1) :\n",
    "        XPATH = '/html/body/main/div/section/div/div[2]/section/div/div[2]/div[15]/div/div['+str(i)+']'\n",
    "        x = browser.find_element(By.XPATH, XPATH)\n",
    "        classx = x.get_attribute('class')\n",
    "        if len(classx) > 15 :\n",
    "            continue\n",
    "        XPATH = '/html/body/main/div/section/div/div[2]/section/div/div[2]/div[15]/div/div['+str(i)+']/div/div/div/div[2]/a'\n",
    "        x = browser.find_element(By.XPATH, XPATH)\n",
    "        scrapping[i] = x.get_attribute('href')\n",
    "        scrapping2={}\n",
    "\n",
    "    for i in scrapping.keys() :\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            request_text = request.urlopen(scrapping[i]).read()\n",
    "            page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "            scrapping2[i]={}\n",
    "        \n",
    "            prix = page.find('h1')\n",
    "            if prix != None :\n",
    "                scrapping2[i]['Prix (€)'] = prix.text[:-2]\n",
    "            else : \n",
    "                scrapping2[i]['Prix (€)'] = float('nan')\n",
    "        \n",
    "            marque = page.find('a', class_ = 'inverse u-disable-underline-without-hover')\n",
    "            if marque != None :\n",
    "                scrapping2[i]['Marque'] = marque.text\n",
    "            else : \n",
    "                scrapping2[i]['Marque'] = float('nan')\n",
    "        \n",
    "            taille = page.find(size_selector)\n",
    "            if taille != None :\n",
    "                end = taille.text.find('Size information')\n",
    "                scrapping2[i]['Taille'] = taille.text[:end]\n",
    "            else : \n",
    "                scrapping2[i]['Taille'] = float('nan')\n",
    "    \n",
    "            etat = page.find(condition_selector)\n",
    "            if etat != None :\n",
    "                end = etat.text.find('Condition information')\n",
    "                scrapping2[i]['Etat'] = etat.text[:end]\n",
    "            else : \n",
    "                scrapping2[i]['Etat'] = float('nan')\n",
    "        \n",
    "            matiere = page.find(material_selector)\n",
    "            if matiere != None :\n",
    "                scrapping2[i]['Matière'] = matiere.text[:end]\n",
    "            else : \n",
    "                scrapping2[i]['Matière'] = float('nan')\n",
    "        \n",
    "            localisation = page.find(loc_selector)\n",
    "            if localisation != None :\n",
    "                scrapping2[i]['Localisation'] = localisation.text[12:]\n",
    "            else : \n",
    "                scrapping2[i]['Localisation'] = float('nan')\n",
    "        \n",
    "            paiement = page.find(paymeth_selector)\n",
    "            if paiement != None :\n",
    "                scrapping2[i]['Option de paiement'] = paiement.text[19:]\n",
    "            else : \n",
    "                scrapping2[i]['Option de paiement'] = float('nan')\n",
    "        \n",
    "            vues = page.find(nbrview_selector)\n",
    "            if vues != None :\n",
    "                scrapping2[i]['Vues'] = vues.text[14:]\n",
    "            else :\n",
    "                scrapping2[i]['Vues'] = float('nan')\n",
    "    \n",
    "            date_ajout = page.find(added_selector)\n",
    "            if date_ajout != None :\n",
    "                scrapping2[i][\"Date d'ajout\"] = date_ajout.attrs['title']\n",
    "            else : \n",
    "                scrapping2[i][\"Date d'ajout\"] = float('nan')\n",
    "        except HTTPError :\n",
    "            pass\n",
    "    firstkey = list(scrapping2.keys())[0]\n",
    "    df = pandas.DataFrame.from_dict(scrapping2, orient = 'index', columns = scrapping2[firstkey].keys())\n",
    "    df = df.transpose(copy=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eee08a57-3ead-4a88-a1a4-04c4a4d5b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_url(x) :\n",
    "    wordlist = x.split()\n",
    "    x = wordlist[0]\n",
    "    if len(wordlist)>1 :\n",
    "        for i in wordlist[1:] :\n",
    "            x = x+'+'+str(i)\n",
    "        return x\n",
    "    else :\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5e77d34-fb5a-46c4-8b6a-fb540cd4761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_selector(tag):\n",
    "\treturn tag.name == \"div\" and tag.has_attr(\"itemprop\") and 'size' in tag.get(\"itemprop\")\n",
    "def condition_selector(tag):\n",
    "\treturn tag.name == \"div\" and tag.has_attr(\"itemprop\") and 'condition' in tag.get(\"itemprop\")\n",
    "def material_selector(tag):\n",
    "\treturn tag.name == \"div\" and tag.has_attr(\"itemprop\") and 'material' in tag.get(\"itemprop\")\n",
    "def loc_selector(tag):\n",
    "\treturn tag.name == \"div\" and tag.has_attr(\"data-testid\") and 'item-details-location' in tag.get(\"data-testid\")\n",
    "def paymeth_selector(tag):\n",
    "\treturn tag.name == \"div\" and tag.has_attr(\"data-testid\") and 'item-details-payment_methods' in tag.get(\"data-testid\")\n",
    "def nbrview_selector(tag):\n",
    "\treturn tag.name == \"div\" and tag.has_attr(\"data-testid\") and 'item-details-view_count' in tag.get(\"data-testid\")\n",
    "def added_selector(tag):\n",
    "\treturn tag.name == \"span\" and tag.has_attr(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17816fb3-adc5-4ae7-99fd-f860fa40c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prix (€)</th>\n",
       "      <td>1,50</td>\n",
       "      <td>1,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marque</th>\n",
       "      <td>Orchestra</td>\n",
       "      <td>TAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taille</th>\n",
       "      <td>8 ans / 128 cm</td>\n",
       "      <td>5 ans / 110 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etat</th>\n",
       "      <td>Très bon état</td>\n",
       "      <td>Très bon état</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matière</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Localisation</th>\n",
       "      <td>Damazan, France</td>\n",
       "      <td>Saint-Claude, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Option de paiement</th>\n",
       "      <td>Carte bancaire</td>\n",
       "      <td>Carte bancaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vues</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date d'ajout</th>\n",
       "      <td>12/25/2023, 11:55:12 AM</td>\n",
       "      <td>12/25/2023, 5:31:20 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          1                       2\n",
       "Prix (€)                               1,50                    1,00\n",
       "Marque                            Orchestra                     TAO\n",
       "Taille                       8 ans / 128 cm          5 ans / 110 cm\n",
       "Etat                          Très bon état           Très bon état\n",
       "Matière                                 NaN                     NaN\n",
       "Localisation                Damazan, France    Saint-Claude, France\n",
       "Option de paiement           Carte bancaire          Carte bancaire\n",
       "Vues                                     17                       2\n",
       "Date d'ajout        12/25/2023, 11:55:12 AM  12/25/2023, 5:31:20 PM"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableau('pull à paillettes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d10bc169-bf71-497a-b528-e35ecf6eec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.vinted.fr/catalog?search_text=pull+rose\n"
     ]
    }
   ],
   "source": [
    "x = raw_to_url('pull rose')\n",
    "print('https://www.vinted.fr/catalog?search_text='+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96989147-a9fd-4930-81be-d94b5e31d790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
